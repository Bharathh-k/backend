# generate_signal.py
import ast
import json
import re
import traceback
from datetime import date

import google.generativeai as genai
import pandas as pd
import requests
from bs4 import BeautifulSoup
from pymongo import MongoClient

from app.config import settings

def safe_json_loads(output: str):
    try:
        # Find the first '{' and last '}' in the response
        start = output.find("{")
        end = output.rfind("}")
        
        if start == -1 or end == -1:
            raise ValueError("No JSON object found in the string.")
        
        json_str = output[start:end+1].strip()
        return json.loads(json_str)
    except Exception as e:
        print(f"❌ JSON parsing failed: {e}")
        print("Raw model output:", output[:500])  # print a preview for debugging
        raise

def generate_stock_signal(news, sector, macro, fundamental, technical, ticker):
    template_path = settings.get_prompt_path("unified_prompt_template.txt")
    with template_path.open("r", encoding="utf-8") as f:
        template = f.read()

    system_prompt = f"""Generate a detailed, objective, and data-driven equity analysis, tailored specifically for Indian retail investors, without generic disclaimers or hedging language. Use precise, quantitative, and qualitative insights with actionable recommendations. Analysis must exclusively focus on equities listed on Indian exchanges (NSE/BSE).
The summaries for each bucket is provided below. Use them to generate a comprehensive analysis. All summaries have been generated by using the latest and accurate data and insights available. If any summary is missing, please fill it with the most relevant and recent data available so that the analysis is complete and actionable.
Only output the summary, strictly following the given format, with no introductions or closing statements from the AI.
Instructions:
- When generating any recommendations in the final recommendation, refer strictly to the data mentioned in the provided summaries. **Do not invent or hallucinate any data.**

Analysis Framework
1.  News Summary
2.  Sectoral News Summary
3.  Macroeconomic Summary
4.  Fundamental Summary
5.  Technical Summary

Final Recommendation for {ticker}
- Action: [ Buy / Hold / Sell ]
- Conviction Level: [ High / Medium / Low ]
- Investment Horizon: [Short-term / Medium-term / Long-term]
- Strategy: (if applicable)

Explicit Reasoning:
- Specific growth targets
- Justification of valuation upside/downside %
- Key catalysts/events with timelines

Risk Management:
- Stop-loss and profit-booking points
- Key metrics/events to monitor

Quality Benchmarks:
- 1500+ words
- Peer comparisons and scenario projections
- Retail-friendly and actionable
""" 

    filled_prompt = template.format(
        news_summary=news,
        sector_summary=sector,
        macro_summary=macro,
        fundamental_summary=fundamental,
        technical_summary=technical
    )

    genai.configure(api_key=settings.gemini_api_key)
    model = genai.GenerativeModel("gemini-2.5-flash", system_instruction=system_prompt, generation_config=genai.GenerationConfig(
        temperature=0,
        top_p=1
    ))

    response = model.generate_content(filled_prompt)
    signal_text = response.text.strip()

    # Save full signal to DB
    try:
        client = MongoClient(settings.mongo_uri, tls=True, tlsAllowInvalidCertificates=True)
        db = client["stock_signal"]
        db["stock_signal_summary"].update_one(
            {"stock": ticker},
            {
              "$set": {
                  "signal": signal_text,
                   "date": date.today().strftime("%Y-%m-%d")
               }
            },
            upsert=True
        )
    finally:
        client.close()

    return signal_text

def extract_and_save_final_recommendation(result, ticker):
    """
    Extracts the final recommendation + generates structured JSON + saves both to DB.
    """
    if "Final Recommendation" in result:
        _, after = result.split("Final Recommendation", 1)
        final_text = "Final Recommendation" + after.strip()
    else:
        final_text = result.strip()

    # MongoDB setup
    client = MongoClient(settings.mongo_uri, tls=True, tlsAllowInvalidCertificates=True)
    db = client["stock_signal"]

    try:
        # Save final recommendation string
        db["final_recommendation"].update_one(
            {"stock": ticker},
            {"$set": {"final_recommendation": final_text}},
            upsert=True
        )
        print(f"✅ Final recommendation for {ticker} saved.")

        # ------------------ STEP 2: Structured JSON extraction ------------------
        df = pd.read_csv(settings.get_data_path("stock(11-06-2025).csv"))
        ticker_row = df[df['SYMBOL'] == ticker]
        roe = (None if ticker_row.empty or pd.isna(ticker_row['ROE'].values[0]) else ticker_row['ROE'].values[0])
        roce = (None if ticker_row.empty or pd.isna(ticker_row['ROCE'].values[0]) else ticker_row['ROCE'].values[0])
        pe = (None if ticker_row.empty or pd.isna(ticker_row['Stock P/E'].values[0]) else ticker_row['Stock P/E'].values[0])
        sales_growth = (None if ticker_row.empty or pd.isna(ticker_row['Compounded Sales Growth'].values[0]) else ticker_row['Compounded Sales Growth'].values[0])
        profit_growth = (None if ticker_row.empty or pd.isna(ticker_row['Compounded Profit Growth'].values[0]) else ticker_row['Compounded Profit Growth'].values[0])
        promoter_raw = None if ticker_row.empty or pd.isna(ticker_row['Promoter holding'].values[0]) else ticker_row['Promoter holding'].values[0]
        promoter_holding = None
        if promoter_raw and isinstance(promoter_raw, str) and promoter_raw.startswith("["):
            try:
                promoter_list = ast.literal_eval(promoter_raw)
                if isinstance(promoter_list, list) and promoter_list:  # non-empty list
                    promoter_holding = promoter_list[-1]
            except Exception:
                promoter_holding = None
        dividend_yield = (None if ticker_row.empty or pd.isna(ticker_row['Dividend Yield'].values[0]) else ticker_row['Dividend Yield'].values[0])
        net_profit_yoy = None
        if not ticker_row.empty and 'np_yearly' in ticker_row:
            try:
                s = ticker_row['np_yearly'].iloc[0]  # get the actual string value
                floats = [float(x.replace(',', '')) for x in ast.literal_eval(s)]
                
                if len(floats) >= 2:
                    latest, prev = floats[-1], floats[-2]
                    if prev != 0:
                        net_profit_yoy = round(((latest - prev) / prev) * 100, 2)
            except Exception as e:
                print(f"Error parsing np_yearly for {ticker}: {e}")

        print(f"Extracted fundamental metrics for {ticker}: ROE={roe}, ROCE={roce}, P/E={pe}, Sales Growth={sales_growth}, Profit Growth={profit_growth}, Promoter Holding={promoter_holding}, Dividend Yield={dividend_yield}, Net Profit YoY%={net_profit_yoy}")
        df = pd.read_csv(settings.get_data_path("sector_hierarchy.csv"))
        ticker_row = df[df['SYMBOL'] == ticker]
        sector = ticker_row['Level 3'].values[0] if not ticker_row.empty else None
        fundamental_summary = {
            "title": "string",
            "metrics": {
                "roe": roe,
                "roce": roce,
                "pe": pe,
                "sales_growth": sales_growth,
                "profit_growth": profit_growth,
                "promoter_holding": promoter_holding,
                "dividend_yield": dividend_yield,
                "net_profit_yoy": net_profit_yoy
            }
        }
        sector_hierarchy = pd.read_csv(settings.get_data_path("sector_hierarchy.csv"))
        sector = sector_hierarchy[sector_hierarchy['SYMBOL'] == ticker]['Sector'].to_list()[0]
        sector_stocks = sector_hierarchy[sector_hierarchy['Sector'] == sector]['SYMBOL']
        csv_path = settings.get_data_path("stock(11-06-2025).csv")
        df_original = pd.read_csv(csv_path)
        df_original["Market Cap"] = df_original["Market Cap"].fillna("").astype(str).str.replace(',', '', regex=False)
        df_original["Market Cap"] = df_original["Market Cap"].replace('', float('nan')).astype(float)        
        top_stocks = df_original[df_original['SYMBOL'].isin(sector_stocks)].nlargest(7, 'Market Cap')
        t = ticker
        for ticker in top_stocks['SYMBOL']:
            url = f"https://www.screener.in/company/{ticker}/consolidated/"
            page = requests.get(url)
            soup = BeautifulSoup(page.content, 'html.parser')
            np_rows = soup.find_all('tr', class_="strong")
            if len(np_rows) < 3:
                return []
            soup_quarterly = BeautifulSoup(str(np_rows[2]), 'html.parser')
            np_quarterly = [td.text.strip() for td in soup_quarterly.find_all('td') if
                            td.text.strip() != '' and (
                                td.text.strip().isdigit() or
                                td.text.strip()[0] == '-' or
                                ',' in td.text.strip() or
                                '.' in td.text.strip())]
            if not np_quarterly:
                url = f"https://www.screener.in/company/{ticker}/"
                page = requests.get(url)
                soup = BeautifulSoup(page.content, 'html.parser')

            try:
                df = pd.read_csv(csv_path)
            except FileNotFoundError:
                df = pd.DataFrame()  # empty if file doesn't exist

            if not df.empty and 'SYMBOL' in df.columns and 'np_quarterly' in df.columns:
                row = df[df['SYMBOL'] == ticker]
                if not row.empty:
                    np_quarterly_csv = row.iloc[0]['np_quarterly']
                    try:
                        np_quarterly_csv = ast.literal_eval(np_quarterly_csv)
                    except Exception:
                        pass
                else:
                    np_quarterly_csv = None
            else:
                np_quarterly_csv = None

            name = soup.find_all(class_="name")
            list_name = [j.get_text().strip() for j in name]
            cleaned_list = ["SYMBOL"] + list_name

            values = soup.find_all(class_="number")
            list_values = [ticker] + [j.get_text() for j in values]

            # Fix High/Low formatting like original code
            if len(list_values) > 4:
                high_low = list_values[3] + "/" + list_values[4]
                list_values[3] = high_low
                for i in range(4, 10):
                    if i + 1 < len(list_values):
                        list_values[i] = list_values[i + 1]
                if len(list_values) > 10:
                    list_values.pop()

            stock_info = dict(zip(cleaned_list, list_values))

            # Net profit quarterly and yearly
            np = soup.find_all('tr', class_="strong")
            if len(np) > 2:
                soup1 = BeautifulSoup(str(np[2]), 'html.parser')
                np_quarterly = [td.text for td in soup1.find_all('td') if (td.text.isdigit() or td.text[0] == '-' or ',' in td.text or '.' in td.text)]
                stock_info["np_quarterly"] = np_quarterly
            if len(np) > 5:
                soup2 = BeautifulSoup(str(np[5]), 'html.parser')
                np_yearly = [td.text for td in soup2.find_all('td') if (td.text.isdigit() or td.text[0] == '-' or ',' in td.text or '.' in td.text)]
                stock_info["np_yearly"] = np_yearly
                stock_info["np_yearly"].pop()

            # Compounded growths
            cg = soup.find_all('table', class_="ranges-table")
            if len(cg) >= 2:
                def extract_ttm(html):
                    soup_cg = BeautifulSoup(html, 'html.parser')
                    table_rows = soup_cg.find_all('tr')
                    for row in table_rows:
                        cells = row.find_all('td')
                        for cell in cells:
                            if cell.text.strip() == 'TTM:':
                                return cell.find_next('td').text.strip()
                    return None

                sales_growth_ttm = extract_ttm(str(cg[0]))
                profit_growth_ttm = extract_ttm(str(cg[1]))
                stock_info["Compounded Sales Growth"] = sales_growth_ttm
                stock_info["Compounded Profit Growth"] = profit_growth_ttm

            # Extract CWIP, Cash Operating Activities, Debtor Days from 'stripe' rows
            stripe_rows = soup.find_all('tr', class_="stripe")
            soup_stripe = BeautifulSoup(str(stripe_rows), 'html.parser')
            rows = soup_stripe.find_all('tr')

            for label in ['CWIP', 'Cash from Operating Activity', 'Debtor Days']:
                for row in rows:
                    if label in row.get_text():
                        values = [cell.get_text().strip() for cell in row.find_all('td')[1:]]
                        key = label if label != 'Cash from Operating Activity' else 'Cash from Operating Activities'
                        stock_info[key] = values
                        break

            # Shareholding patterns
            shrp = soup.find_all('tr')
            soup_shrp = BeautifulSoup(str(shrp), 'html.parser')
            new_shrp = str(soup_shrp).replace('[', '').replace(']', '').split(', ')

            html_snippets = [s for s in new_shrp if any(k in s.lower() for k in ['promoter', 'fii', 'dii', 'public'])]

            promoters, fiis, diis, public = [], [], [], []
            for snippet in html_snippets:
                sub_soup = BeautifulSoup(snippet, 'html.parser')
                percentages = [td.get_text(strip=True) for td in sub_soup.find_all('td') if '%' in td.get_text(strip=True)]
                s_lower = snippet.lower()
                if 'promoters' in s_lower:
                    promoters.extend(percentages)
                elif 'fiis' in s_lower:
                    fiis.extend(percentages)
                elif 'diis' in s_lower:
                    diis.extend(percentages)
                elif 'public' in s_lower:
                    public.extend(percentages)

            stock_info["Promoter holding"] = promoters
            stock_info["FIIs"] = fiis
            stock_info["DIIs"] = diis
            stock_info["Public"] = public

            # Read existing CSV to update or create new list of rows
            try:
                existing_df = pd.read_csv(csv_path)
                # Check if ticker exists; if yes, update, else append
                if ticker in existing_df['SYMBOL'].values:
                    idx = existing_df.index[existing_df['SYMBOL'] == ticker][0]
                    for col in stock_info:
                        value = stock_info[col]
                        # Convert numeric strings to float to avoid dtype warning
                        if isinstance(value, str):
                            try:
                                value = float(value.replace(',', ''))
                            except ValueError:
                                pass  # keep original if not a number
                        existing_df.at[idx, col] = value
                else:
                    existing_df = pd.concat([existing_df, pd.DataFrame([stock_info])], ignore_index=True)
            except FileNotFoundError:
                existing_df = pd.DataFrame([stock_info])
            # Save updated CSV
            existing_df.to_csv(csv_path, index=False)
        ticker = t
        peer_comparison = []
        df = pd.read_csv(settings.get_data_path("stock(11-06-2025).csv"))
        for _, row in df[df['SYMBOL'].isin(top_stocks['SYMBOL'])].iterrows():
            peer_comparison.append({
                "company": row['SYMBOL'],
                "market_cap": str(row['Market Cap']),
                "pe": str(row['Stock P/E']) if pd.notna(row['Stock P/E']) else None,
                "roe": str(row['ROE']),
                "roce": str(row['ROCE'])
            })

        # Final JSON
        output_peer = {"peer_comparison": peer_comparison}
        df_original.to_csv(csv_path, index=False)

        extraction_prompt = '''
    You are a financial data structuring assistant.

    Below is a detailed equity analysis report. Your task is to extract key insights and convert the entire report into a valid JSON object, strictly following the structure below:
    Whatever is hardcoded with values in the JSON structure, must be filled with the same values, do not change them.

    ⚠️ ONLY output the JSON because the output generated by you is directly stored in a variable and passed to convert from string to JSON using json.loads(). DO NOT include explanations or markdown formatting like triple backticks.

    {
      "ticker": "string",
      "company_name": "string",
      "sections": {
        "news_summary": {
          "title": "string",
          "highlights": ["string", "..."]
        },
        "sectoral_summary": {
          "sector": {sector},
          "title": "string",
          "highlights": ["string", "..."]
        },
        "macroeconomic_summary": {
          "title": "string",
          "highlights": ["string", "..."]
        },
        "final_recommendation": {
          "action": "string",
          "buy_on_dips": boolean,
          "buy_levels": ["string"],
          "target_price_range": ["string"],
          "conviction_level": "string",
          "conviction_confidence_percentage": float,
          "investment_horizon": "string",
          "strategy": "string",
          "stop_loss": "string",
          "profit_booking_zone": ["string"]
        },
        "risk_monitoring": ["string"]
      },
      "investor_persona": "string", ("Value Investor", "Growth Investor", "Income Investor", "Momentum Investor", "Contrarian Investor", "Defensive Investor", "Speculative Investor", "ESG/Impact Investor") (chose one),
      "bite_sized_insights": ["string"]  (generate as many unique insights as possible, only from the report, do not hallucinate or add extra insights)
    }
    ⚠️ Requirements:

    All fields must be filled.

    Use correct numeric types (float, int) and plain strings.


    Only return the JSON object with no extra text, code formatting, or explanations.

    Now, here is the equity report for the stock {ticker}:

    {result}
    '''.replace("{result}", result).replace("{ticker}", ticker).replace("{sector}", sector)

        genai.configure(api_key=settings.gemini_api_key)

        model = genai.GenerativeModel("gemini-2.5-flash", generation_config=genai.GenerationConfig(
        temperature=0,
        top_p=1
    ))
        response = model.generate_content(extraction_prompt)
        structured_output = response.text.strip()
        structured_json = safe_json_loads(structured_output)
        print(structured_json)
        tech = db['json_tech']
        output_tech = tech.find_one({"stock": ticker}).get("technical_summary", {})
        structured_json['sections']['technical_summary'] = output_tech
        structured_json['sections']['fundamental_summary'] = fundamental_summary
        structured_json['sections']['fundamental_summary']['peer_comparison'] = output_peer
        # Save to MongoDB
        db["json"].update_one(
            {"stock": ticker},
            {
                "$set": {
                    "extracted_json": structured_json,
                    "date": date.today().strftime("%Y-%m-%d")
                }
            },
            upsert=True
        )
        print(f"✅ Structured JSON for {ticker} saved.")

    except Exception as e:
        print(f"❌ Error extracting/saving JSON for {ticker}: {e}")
        traceback.print_exc()
        raise

    finally:
        client.close()

    return final_text
